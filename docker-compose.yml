version: '3'

services:

  rabbitmq:
    image: rabbitmq:3.7.4

  mongo:
    image: mongo
    ports:
    - "27017:27017"

  backend:
    build: 
      context: ./backend
      dockerfile: Dockerfile
    working_dir: /usr/src/app
    expose:
      - "8080"
    ports:
      - "8080:8080"
    volumes:
      - ./backend:/usr/src/app
      - ./backend:/app
    environment:
      - MESSAGE_QUEUE=amqp://rabbitmq
      - DATABASE_NAME=indeed
      - DB_CONNECTION_STRING=mongodb://mongo:27017/
      - LOAD_ACTIVE_TASKS_ON_START=false
      - MAX_TASKS_PER_USER=2
    links:
      - rabbitmq
    depends_on:
    - mongo
    - rabbitmq
    # logging:
      # driver: syslog
      # options:
        # tag: docker/website
        # syslog-address: "udp://localhost:514"
        # "syslog-address": "udp://1.2.3.4:1111"
        # syslog-format: "rfc3164"

  frontend:
    build: ./frontend
    environment:
      - NODE_ENV=development
    expose:
      - "3000"
    ports:
      - '3000:3000'    
    volumes:
      - '${PWD}:/usr/src/app'
      - '/usr/src/app/node_modules'
    links:
      - backend
    command: [ "npm", "start" ]
    depends_on:
    - backend
    - mongo


  worker:
    build: ./scraper
    image: worker
    command: [/bin/sh , ./starter-script.sh]
    environment:
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672
      - DATABASE_NAME=indeed
      - JOB_KEYS_REGEX="jobKeysWithInfo\[\'([A-Za-z0-9]+)\'\] \="
      - DB_PORT=27017
      - TOR_PORT=9051
      - SCRAPING_ON=True
      - SLEEP_TIME=0
      - SLEEP_TIME_POST_TASK=0
      - TOR_ON=False
      # A single page typically has ~17 results...not counting duplicates
      - PAGES_PER_SCRAPE=1
    expose:
      - "9051"
    ports:
      - '9051:9051' 
    links:
      - backend
    depends_on:
      - rabbitmq
      - backend
    restart: 'no'
    volumes: 
      - ./scraper:/scraper

volumes:
  data-volume:
